# Performance configuration targeting ~96GB GPU memory.
# For a conservative baseline, see `config/settings.example.yaml`.
# Adjust paths and values for your local environment. The
# `./init_project.sh` script will also create a baseline `settings.yaml`
# if it does not exist.

databases:
  primary_url: "postgresql+psycopg://vibe:vibe@localhost:5432/vibe_primary"

cache:
  root: "cache"

queues:
  broker_url: "redis://localhost:6379/0"
  result_backend: "redis://localhost:6379/1"
  preprocess_queue: "pre_process"
  main_queue: "process"
  post_process_queue: "post_process"
  default_concurrency: 12     # leverage 96GB GPU with per-process model copies
  post_process_concurrency: 2
  backfill_batch_size: 256

models:
  embedding:
    backend: "siglip"
    model_name: "google/siglip2-base-patch16-224"
    device: "auto"
    batch_size: 12

  caption:
    backend: "blip"
    model_name: "Salesforce/blip-image-captioning-base"
    device: "auto"
    batch_size: 6

  detection:
    enabled: true
    backend: "owlvit"        # or "grounding-dino" in future milestones
    model_name: "google/owlvit-base-patch32"
    device: "auto"
    max_regions_per_image: 5
    score_threshold: 0.26
    # Class-agnostic non-max suppression for overlapping boxes.
    nms_iou_threshold: 0.8
    # Primary region priority weights (area + distance to center).
    primary_area_gamma: 0.3
    primary_center_penalty: 0.6
    # Caption-based primary region fallback.
    caption_primary_enabled: true
    caption_primary_min_priority: 0.02
    caption_primary_box_margin_x: 0.2
    caption_primary_box_margin_y: 0.1
    caption_primary_use_label_groups: true    # derive fallback keywords from models.siglip_labels.label_groups
    # Filter out low-priority secondary regions after sorting.
    secondary_min_priority: 0.03
    secondary_min_relative_to_primary: 0.3

  ocr:
    enabled: false           # M1 MUST work with OCR disabled

  # Shared SigLIP label dictionaries for region re-ranking, diagnostics,
  # and prototype detectors. Keeping these in configuration avoids
  # duplicating label lists across modules.
  siglip_labels:
    # Coarse semantic groups for SigLIP labels. Used as the single
    # source of truth for:
    #   - region re-ranking candidate labels,
    #   - mapping detector labels to semantic groups,
    #   - and SimpleDetector label prompts.
    # Downstream code flattens this mapping to build candidate label
    # lists and human-friendly category prompts.
    label_groups:
      food:
        - "food"
        - "tapas"
        - "pizza"
        - "burger"
        - "pie"
        - "sushi"
        - "noodles"
        - "bread"
        - "toast"
        - "dessert"
        - "cake"
        - "steak"
        - "meat"
        - "drink"
        - "butter"
        - "cheese"
        - "sauce"
        - "soup"
        - "beverage"
        - "glass of drink"
        - "cocktail"
        - "juice"
        - "coffee"
        - "tea"
        - "beer"
        - "wine"
        - "soft drink"
      electronics:
        - "phone"
        - "smartphone"
        - "iPhone"
        - "Android phone"
        - "computer"
        - "laptop"
        - "MacBook"
        - "tablet"
        - "iPad"
        - "headphones"
        - "AirPods"
        - "camera"
      document:
        - "document"
        - "book"
        - "notes"
      person:
        - "person"
        - "people"
      scene:
        - "landscape"
        - "architecture"
        - "building"
      animal:
        - "animal"
        - "pet"
      specific_products:
        - "iPhone"
        - "MacBook"
        - "iPad"
        - "AirPods"
        - "Samsung Galaxy"
        - "ThinkPad"
        - "Surface"

pipeline:
  # Whether to run detection step.
  run_detection: true
  # Whether to run clustering passes.
  run_cluster: true
  # Whether to skip heavy models for near-duplicates.
  skip_duplicates_for_heavy_models: true
  # Hamming distance threshold for near-duplicate grouping (default 12).
  phash_hamming_threshold: 16
  # Target thumbnail sizes (max width/height in pixels) for web previews.
  thumbnail_size_small: 256
  thumbnail_size_large: 1024
  # JPEG quality (1â€“100) for thumbnails.
  thumbnail_quality: 85
  # How to store EXIF datetime in the database: "raw" uses the original camera string;
  # "iso" normalizes to an ISO-8601-like "YYYY-MM-DDTHH:MM:SS" format when parsing succeeds.
  exif_datetime_format: "iso"

label_spaces:
  scene_current: "scene_v1"
  object_current: "object_v1"
  cluster_current: "cluster_v1"

scene:
  top1_min_score: 0.30

attributes:
  has_person:
    face_score_min: 0.35
  has_text:
    score_min: 0.35
  is_document:
    score_min: 0.60
  is_screenshot:
    score_min: 0.55

object:
  zero_shot:
    top_k: 5
    score_min: 0.32
    margin_min: 0.08
    scene_whitelist:
      - "scene.product"
      - "scene.food"
    # Optional per-scene fallback allowlists (e.g., screenshot/doc minimal labels)
    scene_fallback_labels: {}
  aggregation:
    min_regions: 1
    score_min: 0.32
  blacklist:
    - "object.food.butter"
    - "object.food.water"
    - "object.food.sauce"
  remap:
    "object.food.glass of drink": "object.drink"
    "object.electronics.phone": "object.electronics.phone"

cluster:
  image:
    k: 20
    sim_threshold: 0.78
    min_size: 3
  region:
    k: 20
    sim_threshold: 0.82
    min_size: 3
